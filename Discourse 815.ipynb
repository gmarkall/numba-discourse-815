{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "032c4a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from numba import cuda\n",
    "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_normal_float32\n",
    "from time import perf_counter\n",
    "size = (1024, 2, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7990fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.2 ms ± 296 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# With numpy\n",
    "%timeit np.random.normal(size=size)\n",
    "# 59.1 ms ± 1.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda101da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 µs ± 13.5 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# With cupy\n",
    "%timeit cp.random.normal(size=size, dtype=cp.float32); cp.cuda.Device().synchronize()\n",
    "# 48.4 µs ± 112 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57b1dd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745 µs ± 2.75 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# With numba.cuda\n",
    "@cuda.jit\n",
    "def numba_cuda_normal(rng_states, out):\n",
    "    pos = cuda.grid(1)\n",
    "    for i in range(out.shape[2]):\n",
    "        out[pos, 0, i] = xoroshiro128p_normal_float32(rng_states, pos)\n",
    "        out[pos, 1, i] = xoroshiro128p_normal_float32(rng_states, pos)\n",
    "\n",
    "threads_per_block = 8 # Best performance reach for threads_per_block=8 with RTX3080\n",
    "blocks = size[0]//threads_per_block\n",
    "rng_states = create_xoroshiro128p_states(threads_per_block * blocks, seed=1)\n",
    "out = np.zeros(size, dtype=np.float32)\n",
    "out_gpu = cuda.to_device(out)\n",
    "numba_cuda_normal[blocks, threads_per_block](rng_states, out_gpu) # warmup\n",
    "%timeit numba_cuda_normal[blocks, threads_per_block](rng_states, out_gpu); cuda.synchronize()\n",
    "# 701 µs ± 869 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12df0b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time is 157.67731770001774 µs per iteration\n"
     ]
    }
   ],
   "source": [
    "# Modified version for numba.cuda\n",
    "\n",
    "# This kernel maps thread index x to shape[0] and y to shape[2], so that more\n",
    "# threads can be launched in parallel. The loop over shape[2] is replaced with\n",
    "# the second thread index\n",
    "@cuda.jit\n",
    "def numba_cuda_normal_2(rng_states, out):\n",
    "    pos, i = cuda.grid(2)\n",
    "    \n",
    "    # Ensure our thread is within the bounds of the array\n",
    "    if pos < out.shape[0] and i < out.shape[2]:\n",
    "        out[pos, 0, i] = xoroshiro128p_normal_float32(rng_states, pos * out.shape[2] + i)\n",
    "        out[pos, 1, i] = xoroshiro128p_normal_float32(rng_states, pos * out.shape[2] + i)\n",
    "\n",
    "# 256 threads / 8 warps per block - a reasonable, slightly arbitrary choice\n",
    "threads_per_block = (16, 16) \n",
    "\n",
    "# Launch enough blocks for all data points.\n",
    "# Sometimes this will launch slightly more blocks than needed -\n",
    "# the calculation could be improved slightly\n",
    "blocks = ((size[0] // threads_per_block[0]) + 1, (size[2] // threads_per_block[1]) + 1)\n",
    "\n",
    "# RNG state initialization\n",
    "rng_states = create_xoroshiro128p_states(size[0] * size[2], seed=1)\n",
    "\n",
    "# Create output array on GPU and warm up JIT\n",
    "out = np.zeros(size, dtype=np.float32)\n",
    "out_gpu = cuda.to_device(out)\n",
    "numba_cuda_normal_2[blocks, threads_per_block](rng_states, out_gpu) # warmup\n",
    "\n",
    "# How many iterationss to loop through when timing?\n",
    "N_ITERATIONS = 10000\n",
    "\n",
    "# Timing: we launch all kernels then synchronize after launching all kernels\n",
    "# before recording the end timer - this way we avoid including one sync\n",
    "# per iteration in our timing.\n",
    "\n",
    "start = perf_counter()\n",
    "\n",
    "for i in range(N_ITERATIONS):\n",
    "    numba_cuda_normal_2[blocks, threads_per_block](rng_states, out_gpu)\n",
    "\n",
    "cuda.synchronize()\n",
    "end = perf_counter()\n",
    "\n",
    "\n",
    "# Iteration time is total time dividide by number of iterations\n",
    "# Time is given in seconds, so multiply to get microseconds\n",
    "iteration_time = ((end - start) / N_ITERATIONS) * 1_000_000\n",
    "\n",
    "print(f\"Time is {iteration_time} µs per iteration\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
